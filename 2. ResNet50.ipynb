{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasminjahanpuspo/CNN_Architectures/blob/main/2.%20ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**<font color='yellow'>Model Name: ResNet50</font>**\n"
      ],
      "metadata": {
        "id": "ErsqFCbL7i55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup Environment"
      ],
      "metadata": {
        "id": "taYt-0Q2jQ7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Mount Google Drive\n",
        "*   Access datasets stored in your Google Drive.\n"
      ],
      "metadata": {
        "id": "XpAB5dRKbqKU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQG5VOHy4zdX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Import Required Libraries\n",
        "*   Load all necessary libraries for image processing, data handling, and visualization.\n",
        "*   Load TensorFlow, Keras, and layers for building CNN models."
      ],
      "metadata": {
        "id": "1TYMYAEqbyUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Libraries for Data Handling\n",
        "# ============================================================\n",
        "import os                      # File and directory operations\n",
        "import glob as gb              # File pattern matching (e.g., get all image paths)\n",
        "import numpy as np             # Numerical operations and arrays\n",
        "import pandas as pd            # Data manipulation and analysis\n",
        "\n",
        "# ============================================================\n",
        "#  Libraries for Image Processing\n",
        "# ============================================================\n",
        "import cv2                     # OpenCV for image reading and preprocessing\n",
        "from PIL import Image          # Image loading and manipulation\n",
        "\n",
        "# ============================================================\n",
        "#  Libraries for Visualization\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt # Plotting graphs and images\n",
        "import seaborn as sns           # Advanced visualizations (e.g., heatmaps)\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "\n",
        "# ============================================================\n",
        "#  Utilities and Helpers\n",
        "# ============================================================\n",
        "import random                  # For random sampling and augmentations\n",
        "import math                    # Mathematical operations\n",
        "import time                    # Measure training time and performance\n"
      ],
      "metadata": {
        "id": "yl9sPyjy4_Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TensorFlow & Keras Core Libraries\n",
        "# ============================================================\n",
        "import tensorflow as tf                       # Core TensorFlow library\n",
        "from tensorflow import keras                  # High-level API for deep learning\n",
        "from tensorflow.keras import layers, models   # Layers and model-building utilities\n",
        "\n",
        "# ============================================================\n",
        "# Dataset Utilities\n",
        "# ============================================================\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "# Load and preprocess image datasets from directory structures\n",
        "\n",
        "# ============================================================\n",
        "# Layers for CNN Architectures\n",
        "# ============================================================\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten,\n",
        "    Conv2D, MaxPool2D, LeakyReLU\n",
        ")\n"
      ],
      "metadata": {
        "id": "4nGEvjWn5AqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Prepare Dataset\n",
        "Load and preprocess train, validation, and test datasets for model input."
      ],
      "metadata": {
        "id": "AiFnZABsjKSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Create TensorFlow Datasets\n",
        "\n",
        "\n",
        "*   Load images from the directories into TensorFlow datasets for training, validation, and testing.  \n",
        "*   Adjust `image_size` and `batch_size` as needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "nVdbFrrNcQVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the directories for training, testing, and validation\n",
        "train_directory = '/content/drive/MyDrive/sample_dataset/train'\n",
        "test_directory = '/content/drive/MyDrive/sample_dataset/test'\n",
        "valid_directory = '/content/drive/MyDrive/sample_dataset/valid'"
      ],
      "metadata": {
        "id": "qSyUxU6b5BYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)  # define resolution (299,299) /(224,224)\n",
        "BATCH_SIZE = 128       # varies from dataset to datset prefferable 128/68/32"
      ],
      "metadata": {
        "id": "b-HxLOvn5C-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow datasets for training, testing, and validation\n",
        "#you can customize parameters as per dataset\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    shuffle=True,\n",
        "    labels='inferred',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_directory,\n",
        "    shuffle=True,\n",
        "    labels='inferred',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "valid_dataset = image_dataset_from_directory(\n",
        "    valid_directory,\n",
        "    shuffle=True,\n",
        "    labels='inferred',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "lxyfzw5w5GNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically detect number of classes from dataset\n",
        "class_names = train_dataset.class_names  # works with image_dataset_from_directory\n",
        "n_classes = len(class_names)\n",
        "\n",
        "print(\"Detected Classes:\", class_names)\n",
        "print(\"Number of Classes:\", n_classes)"
      ],
      "metadata": {
        "id": "fFY8fkC45MnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = []\n",
        "for i in range(len(train_dataset.class_names)):\n",
        "    class_counts.append(sum(1 for _, label in train_dataset.unbatch().as_numpy_iterator() if label == i))\n",
        "\n",
        "Dataset = class_counts  # now your class weights will adapt automatically"
      ],
      "metadata": {
        "id": "5uNt6oML5TiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Training\n",
        "This step involves setting up the CNN model architecture (e.g., DenseNet121, InceptionV3, ResNet50), configuring the input shape, downloading pretrained weights (e.g., ImageNet), and compiling the model for training."
      ],
      "metadata": {
        "id": "n_GMjBaXOpD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Initialize Base Model\n",
        "*   Download pretrained weights and load the base CNN model.  "
      ],
      "metadata": {
        "id": "ScZqSLcl-GQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_learning_rate = 0.001 # prefferable lr is 0.0001 or 0.001\n",
        "IMG_SHAPE = IMG_SIZE +(3,)"
      ],
      "metadata": {
        "id": "-OalbxVyBbHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### ðŸ”¹ Download pretrained weights and initialize base model\n",
        "*  Load the CNN base model with pretrained weights for transfer learning.  "
      ],
      "metadata": {
        "id": "BDUNUBd2-OZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## N.B:download the weights (imagenet/...) and model (Resnet50/ResNet100/InceptionV3...)\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top= False, weights='imagenet')"
      ],
      "metadata": {
        "id": "tl9Pm1lQO6Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Preprocessing function\n",
        "*   Apply model-specific preprocessing to input images.  \n",
        "\n"
      ],
      "metadata": {
        "id": "HKXtYC0m-fRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(base_model)\n",
        "## N.B: change the model name\n",
        "preprocess_input = tf.keras.applications.resnet.preprocess_input"
      ],
      "metadata": {
        "id": "wJWvn2iEO92h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Model summary info\n",
        "*   View layer-wise details of the base model.  "
      ],
      "metadata": {
        "id": "NTlJgE2U-k-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_layers = len(base_model.layers)\n",
        "print(\"Numbers of Layers =\" , nb_layers)\n",
        "print(base_model.layers[nb_layers - 2].name)  # pre- Last name\n",
        "print(base_model.layers[nb_layers - 1].name)"
      ],
      "metadata": {
        "id": "hHByKSYiPAfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all layers with index, name, and type\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    print(i, layer.name, layer.__class__.__name__)\n"
      ],
      "metadata": {
        "id": "k8hQOmN9CTQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Feature extraction preview\n",
        "*   Inspect features extracted from input images by the base model."
      ],
      "metadata": {
        "id": "myeBvvaw-qiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over first batch (32 image) in trainset\n",
        "image_batch, label_batch = next(iter(train_dataset))  # 32 image arrays\n",
        "feature_batch = base_model(image_batch)  # run the model on those 32 image (base model with its 1000 causes classification)\n",
        "print(feature_batch.shape)  # 32 for number of images in this batch and 1000 for classes"
      ],
      "metadata": {
        "id": "02wLshtjPBxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Create custom classification model\n",
        "*  Add dense/classification layers on top of the base model.  "
      ],
      "metadata": {
        "id": "2keEM0hw-uf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model( image_shape=IMG_SHAPE):\n",
        "    ''' Define a tf.keras model for multi-class classification out of the *model name* (Resnet/Inception...) '''\n",
        "    ##change the *model name*\n",
        "    downloaded_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top= False, weights='imagenet')\n",
        "    downloaded_model.trainable = True\n",
        "    for layer in downloaded_model.layers[0 : 291]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(image_shape)\n",
        "    x = preprocess_input(inputs)\n",
        "    x = downloaded_model(x , training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    prediction_layer = tf.keras.layers.Dense(n_classes ,activation = \"softmax\")   ## change the first parameter according to the class len\n",
        "    outputs = prediction_layer(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "2NduUW5uqltJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Instantiate the model\n",
        "*   Initialize the full model with custom layers."
      ],
      "metadata": {
        "id": "s4ajH06w-1i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## specify function name as model name\n",
        "model = create_model(IMG_SHAPE)"
      ],
      "metadata": {
        "id": "IA6HsX4xY_k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Build and Compile Model\n",
        "*   Define optimizer, loss function, and metrics for training."
      ],
      "metadata": {
        "id": "TcDQYth5yO-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## customize optimizer as Nadam or Adam\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=base_learning_rate),\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                           metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5snFX_C-cbRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Model Checkpoint & Save\n",
        "* Save the best model during training using **checkpoints**, and optionally save the final trained model.\n"
      ],
      "metadata": {
        "id": "gMB_XqzjyWwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "## set the path name as *dataset/Lr/optimizer_name/model_name*\n",
        "model_filepath=\"/content/drive/MyDrive/sample_dataset/ResNet50-{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath = model_filepath ,\n",
        "    monitor ='val_accuracy',\n",
        "    mode = 'max' ,\n",
        "    save_best_only =True ,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "EebFVeeCc6et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Load / Set Model Weights\n",
        "* Load pre-trained weights or initialize custom weights for the CNN model.\n"
      ],
      "metadata": {
        "id": "9SOF1pFMySmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you already have Dataset as a list of samples per class\n",
        "# or you can compute from train_dataset using:\n",
        "# class_counts = [sum(1 for _, label in train_dataset.unbatch().as_numpy_iterator() if label==i) for i in range(n_classes)]\n",
        "\n",
        "total = sum(Dataset)        # total number of images\n",
        "class_weight = {}\n",
        "\n",
        "for i, count in enumerate(Dataset):\n",
        "    class_weight[i] = (1 / count) * (total / len(Dataset))\n",
        "\n",
        "# Print class weights\n",
        "for i, w in class_weight.items():\n",
        "    print(f\"Weight for class {i}: {w:.2f}\")\n"
      ],
      "metadata": {
        "id": "uGvh9SVQq8Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Train the Model\n",
        "* Train the CNN model using the training dataset, validate on the validation dataset, and store the training history.\n"
      ],
      "metadata": {
        "id": "MQ70xk06BAhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start timer before training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "## change hyperparameter such as epoches\n",
        "history = model.fit(train_dataset , verbose=2 , epochs=5 , class_weight=class_weight ,                         validation_data=valid_dataset ,\n",
        "                    callbacks =[checkpoint])\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training duration in minutes\n",
        "training_time_mins = (end_time - start_time) / 60\n",
        "\n",
        "print(f\"ðŸ•’ Total Training Time: {training_time_mins:.2f} minutes\")"
      ],
      "metadata": {
        "id": "ASDsHJqQdXk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Test the Model\n",
        "* Evaluate the trained model on the test dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FvO1L9xt_hHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset , verbose = 1)"
      ],
      "metadata": {
        "id": "iDopjvLRdc0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Results & Visualizations\n",
        "Evaluate model performance and visualize key metrics and results."
      ],
      "metadata": {
        "id": "1xZYuYqJiV23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Actual vs Predicted Classes\n",
        "\n",
        "*  Visualize the modelâ€™s predictions compared to true labels on the test dataset.\n",
        "*   Collect **one example per class** from `test_dataset`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4IHIo3cXhioh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = {}\n",
        "for images, labels in test_dataset.unbatch().take(1000):  # take enough to find all classes\n",
        "    class_idx = labels.numpy()\n",
        "    if class_idx not in examples:\n",
        "        examples[class_idx] = images\n",
        "    if len(examples) == n_classes:\n",
        "        break\n",
        "\n",
        "# Plotting\n",
        "cols = 2  # number of columns\n",
        "rows = math.ceil(n_classes / cols)\n",
        "plt.figure(figsize=(cols * 5, rows * 5))\n",
        "\n",
        "for i, class_idx in enumerate(sorted(examples.keys())):\n",
        "    img = examples[class_idx].numpy().astype(\"uint8\")\n",
        "    img_exp = tf.expand_dims(img, 0)  # expand batch dim\n",
        "    predict = model.predict(img_exp)\n",
        "    predicted = class_names[np.argmax(predict)]\n",
        "    actual = class_names[class_idx]\n",
        "\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    color = 'blue' if predicted == actual else 'red'\n",
        "    plt.title(f\"Pred: {predicted}\\nActual: {actual}\", fontsize=12, fontweight='bold', color=color)\n",
        "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9,\n",
        "                        top=0.9, wspace=0.4, hspace=0.4)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q6tp2J0udexP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Actual vs Predicted Images\n",
        "\n",
        "*   Display sample images from the test set with their **true labels and model predictions** for qualitative evaluation.\n",
        "*   Show **three images per class** for qualitative evaluation.\n"
      ],
      "metadata": {
        "id": "fMbwgPYpELfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load multiple random images per class\n",
        "def load_images_per_class(folder, num_images_per_class=3):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = []\n",
        "\n",
        "    for class_idx, subfolder in enumerate(sorted(os.listdir(folder))):\n",
        "        subfolder_path = os.path.join(folder, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            class_names.append(subfolder)\n",
        "            image_files = os.listdir(subfolder_path)\n",
        "            selected_files = random.sample(image_files, min(num_images_per_class, len(image_files)))\n",
        "            for image_file in selected_files:\n",
        "                img_path = os.path.join(subfolder_path, image_file)\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                img = img.resize((64, 64))\n",
        "                images.append(np.array(img)/255.0)\n",
        "                labels.append(class_idx)\n",
        "\n",
        "    return np.array(images), np.array(labels), class_names\n",
        "\n",
        "# Path to your test folder\n",
        "test_folder = '/content/drive/MyDrive/sample_dataset/test'\n",
        "\n",
        "# Load images: change num_images_per_class as needed\n",
        "num_images_per_class = 3\n",
        "images, labels, class_names = load_images_per_class(test_folder, num_images_per_class=num_images_per_class)\n",
        "\n",
        "# Example predicted labels (replace with your model predictions)\n",
        "predicted_labels = labels.copy()  # For demo, assume correct predictions\n",
        "\n",
        "# Automatically calculate subplot grid\n",
        "total_images = len(images)\n",
        "cols = 2  # Original + Predicted\n",
        "rows = total_images  # Each image gets a row\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*5, rows*4))\n",
        "\n",
        "if rows == 1:  # Special case if only 1 image\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "for i in range(total_images):\n",
        "    img = images[i]\n",
        "    true_label = class_names[labels[i]]\n",
        "    predicted_label = class_names[predicted_labels[i]]\n",
        "\n",
        "    # Original\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f'True: {true_label}', fontsize=12, fontweight='bold')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Predicted\n",
        "    axes[i, 1].imshow(img)\n",
        "    color = 'blue' if true_label == predicted_label else 'red'\n",
        "    axes[i, 1].set_title(f'Predicted: {predicted_label}', fontsize=12, fontweight='bold', color=color)\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7cdLNVIyELfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Label Binarization\n",
        "* Binarize class labels and evaluate model performance using metrics like **accuracy, precision, recall, and F1-score**.\n"
      ],
      "metadata": {
        "id": "-IVeTL6Ks5Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Initialize empty lists to store true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterate through the validation dataset and make predictions\n",
        "for images, labels in test_dataset:\n",
        "    predictions = model.predict(images)\n",
        "    predicted_labels.extend(np.argmax(predictions, axis=1))\n",
        "    true_labels.extend(labels.numpy())\n",
        "\n",
        "# Binarize the true and predicted labels\n",
        "true_labels_bin = label_binarize(true_labels, classes=np.unique(true_labels))\n",
        "predicted_labels_bin = label_binarize(predicted_labels, classes=np.unique(predicted_labels))"
      ],
      "metadata": {
        "id": "e9WMIn6qspog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Classification Report\n",
        "* Provides precision, recall, F1-score, and support for each class to summarize model performance.\n"
      ],
      "metadata": {
        "id": "TtyzzXJ4qarM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "id": "dS3ZX7Srqa4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Confusion Matrix\n",
        "* Visualize the **confusion matrix** to assess class-wise prediction performance."
      ],
      "metadata": {
        "id": "BFTLc07BEFoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(5, 3))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix', fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z7W9rd-BEFo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ“ˆ Training and Validation Accuracy & Training and Validation Loss\n",
        "* Visualize the model's **training and validation accuracy and loss** over epochs to assess learning and overfitting."
      ],
      "metadata": {
        "id": "Htax3AetEK-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [0.] + history.history['accuracy']\n",
        "val_acc = [0.] + history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(17, 12))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,3.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eWY5-AokEK-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ“ˆ ROC curve\n",
        "*   Plot the **ROC curve** to evaluate model performance.\n",
        "*  **One-vs-Rest** for multiclass and\n",
        " **One-vs-One** for binary classification."
      ],
      "metadata": {
        "id": "ybdZaU84rNYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Get true labels and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_dataset:     # or valid_dataset if you want\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(preds)\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "print(\"Shape of predictions:\", y_pred.shape)\n"
      ],
      "metadata": {
        "id": "YRVtTDwGti95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize labels for multiclass ROC\n",
        "y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n"
      ],
      "metadata": {
        "id": "gsFzKsa9tnEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Automatically generate colors\n",
        "colors = cm.get_cmap('tab20', n_classes)  # 'tab20' or 'tab10', n_classes colors\n",
        "\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], color=colors(i), lw=2,\n",
        "             label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve', fontweight='bold')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V_N2vWgetpSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Right vs Wrong Classifier\n",
        "* Visualize and analyze **correctly and incorrectly classified samples** to understand model performance."
      ],
      "metadata": {
        "id": "lT_tF8g4nxTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Calculate total right and wrong predictions\n",
        "total_right = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == pred)\n",
        "total_wrong = sum(1 for true, pred in zip(true_labels, predicted_labels) if true != pred)\n",
        "total_samples = len(true_labels)\n",
        "\n",
        "print(\"Total Right Predictions:\", total_right)\n",
        "print(\"Total Wrong Predictions:\", total_wrong)\n",
        "\n",
        "# Calculate percentages\n",
        "right_percentage = (total_right / total_samples) * 100\n",
        "wrong_percentage = (total_wrong / total_samples) * 100\n",
        "\n",
        "# Data for the bar plot\n",
        "labels = ['Right', 'Wrong']\n",
        "percentages = [right_percentage, wrong_percentage]"
      ],
      "metadata": {
        "id": "zBx-i2nE6K-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(labels, percentages, color=['cyan', 'blue'], width=0.6)\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 2, f'{yval:.1f}%',\n",
        "             ha='center',fontsize=14,fontweight='bold', va='bottom')\n",
        "\n",
        "plt.title('Right and Wrong Predictions', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.ylim(0, 110)  # add padding on top\n",
        "plt.axhline(0, color='grey', linewidth=0.8, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qiADXlAJa3ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Model Evaluation Metrics\n",
        "* Summarize the model's performance using multiple metrics: **Accuracy**, **Precision**, **Recall (Sensitivity)**, **F1 Score**, **Negative Predictive Value (NPV)**, **AUC-ROC**"
      ],
      "metadata": {
        "id": "zvOFvFChEQ5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ----- Metric Computation -----\n",
        "n_classes = len(np.unique(true_labels))\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "# Binary: compute NPV and AUC\n",
        "if n_classes == 2:\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "    auc = roc_auc_score(true_labels, predicted_labels)\n",
        "else:\n",
        "    npv = np.nan\n",
        "    auc = np.nan\n",
        "\n",
        "metrics = {\n",
        "    'Accuracy': accuracy * 100,\n",
        "    'Precision': precision * 100,\n",
        "    'Recall': recall * 100,\n",
        "    'F1 Score': f1 * 100,\n",
        "    'NPV': npv * 100 if not np.isnan(npv) else np.nan,\n",
        "    'AUC-ROC': auc * 100 if not np.isnan(auc) else np.nan\n",
        "}\n",
        "\n",
        "# ----- Plotting -----\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bars = plt.bar(metrics.keys(), metrics.values(),\n",
        "               color=['royalblue', 'darkorange', 'mediumseagreen', 'crimson', 'orchid', 'deepskyblue'],\n",
        "               width=0.6, edgecolor='black', linewidth=0.8)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    if not np.isnan(yval):  # skip NaNs\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 1.0, f'{yval:.2f}%',  # show % with 2 decimals\n",
        "                 ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.title('Model Evaluation Metrics', fontsize=14, fontweight='bold', pad=15)\n",
        "plt.ylabel('Score (%)', fontsize=12)\n",
        "plt.ylim(0, 110)  # allow space above 100%\n",
        "plt.axhline(y=50, color='grey', linestyle='--', linewidth=0.8)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oxrbc48yEQ5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print metric values\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "htaqo9ZxEQ5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Cohen's Kappa\n",
        "* Measure agreement between predicted and true labels beyond chance."
      ],
      "metadata": {
        "id": "eb68-JCSEhlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
        "print(f'Cohen\\'s Kappa: {kappa:.4f}')"
      ],
      "metadata": {
        "id": "pyxtqqkiEhlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Matthews Correlation Coefficient (MCC)\n",
        "* Assess overall classification quality considering all confusion matrix terms."
      ],
      "metadata": {
        "id": "9KLT9TVwEhlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "import numpy as np\n",
        "\n",
        "# Assuming true_labels and predicted_labels are multiclass labels\n",
        "mcc_values = [matthews_corrcoef(true_labels == i, predicted_labels == i) for i in np.unique(true_labels)]\n",
        "\n",
        "average_mcc = np.mean(mcc_values)\n",
        "print(f'Average Matthews Correlation Coefficient for Multiclass: {average_mcc:.4f}')"
      ],
      "metadata": {
        "id": "yYj36RuXEhlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Sensitivity & Specificity\n",
        "* Evaluate each class's **sensitivity (recall)** and **specificity** based on true positives and true negatives\n"
      ],
      "metadata": {
        "id": "LAlNmbWKpMWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "# If binary classification\n",
        "if n_classes == 2:\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    print(\"Binary Classification:\")\n",
        "    print(f\"Sensitivity (Recall): {sensitivity:.3f}\")\n",
        "    print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "# If multiclass classification\n",
        "else:\n",
        "    # Sensitivity = TP / (TP + FN)\n",
        "    sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
        "    # Specificity = TN / (TN + FP)\n",
        "    specificity = []\n",
        "    for i in range(n_classes):\n",
        "        # For each class, treat it as \"positive\" vs \"rest\"\n",
        "        tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n",
        "        fp = np.sum(np.delete(cm, i, axis=0)[:, i])\n",
        "        specificity.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
        "    specificity = np.array(specificity)\n",
        "\n",
        "    print(\"Multiclass Classification:\")\n",
        "    for i in range(n_classes):\n",
        "        print(f\"Class {i}: Sensitivity={sensitivity[i]:.3f}, Specificity={specificity[i]:.3f}\")\n",
        "\n",
        "    print(f\"\\nAverage Sensitivity: {np.mean(sensitivity):.3f}\")\n",
        "    print(f\"Average Specificity: {np.mean(specificity):.3f}\")\n"
      ],
      "metadata": {
        "id": "GuMV72ft6S4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Plot Sensitivity and Specificity ---\n",
        "if n_classes == 2:\n",
        "    metrics = ['Sensitivity', 'Specificity']\n",
        "    values = [sensitivity, specificity]\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.bar(metrics, values, color=['#1f77b4', '#ff7f0e'])\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title(\"Binary Classification Metrics\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    x = np.arange(n_classes)\n",
        "    width = 0.35  # Bar width\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, sensitivity, width, label='Sensitivity', color='#1f77b4')\n",
        "    plt.bar(x + width/2, specificity, width, label='Specificity', color='#ff7f0e')\n",
        "\n",
        "    plt.xticks(x, [f'Class {i}' for i in range(n_classes)])\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xlabel(\"Classes\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(\"Per-Class Sensitivity and Specificity\", fontsize=12, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7GtbCbgh6YwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Plot Sensitivity and Specificity ---\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if n_classes == 2:\n",
        "    metrics = ['Sensitivity', 'Specificity']\n",
        "    values = [sensitivity * 100, specificity * 100]  # convert to %\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    bars = plt.bar(metrics, values, color=['#1f77b4', '#ff7f0e'],\n",
        "                   width=0.6, edgecolor='black', linewidth=0.8)\n",
        "\n",
        "    # Add percentage labels on top\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 1.0, f'{yval:.2f}%',\n",
        "                 ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.ylim(0, 110)\n",
        "    plt.title(\"Binary Classification Metrics\", fontsize=13, fontweight='bold', pad=12)\n",
        "    plt.ylabel(\"Score (%)\", fontsize=11)\n",
        "    plt.axhline(y=50, color='grey', linestyle='--', linewidth=0.8)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    # Multiclass case\n",
        "    sensitivity = np.array(sensitivity) * 100\n",
        "    specificity = np.array(specificity) * 100\n",
        "    x = np.arange(n_classes)\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars1 = plt.bar(x - width/2, sensitivity, width, label='Sensitivity', color='#1f77b4', edgecolor='black', linewidth=0.7)\n",
        "    bars2 = plt.bar(x + width/2, specificity, width, label='Specificity', color='#ff7f0e', edgecolor='black', linewidth=0.7)\n",
        "\n",
        "    # Add labels on top of bars\n",
        "    for bar in list(bars1) + list(bars2):\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 1.0, f'{yval:.2f}%',\n",
        "                 ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "    plt.xticks(x, [f'Class {i}' for i in range(n_classes)], fontsize=10)\n",
        "    plt.ylim(0, 110)\n",
        "    plt.xlabel(\"Classes\", fontsize=11)\n",
        "    plt.ylabel(\"Score (%)\", fontsize=11)\n",
        "    plt.title(\"Per-Class Sensitivity and Specificity\", fontsize=13, fontweight='bold', pad=12)\n",
        "    plt.legend()\n",
        "    plt.axhline(y=50, color='grey', linestyle='--', linewidth=0.8)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "k4L3sFVYiNnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zAzgVRz3SioH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M_aU2p4vSjfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Compute Sensitivity & Specificity ---\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "# Sensitivity (macro average): TP / (TP + FN)\n",
        "sensitivity_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
        "sensitivity = np.nanmean(sensitivity_per_class)\n",
        "\n",
        "# Specificity (macro average): TN / (TN + FP)\n",
        "specificity_list = []\n",
        "for i in range(n_classes):\n",
        "    tn = np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1))\n",
        "    fp = np.sum(np.delete(cm, i, axis=0)[:, i])\n",
        "    specificity_list.append(tn / (tn + fp) if (tn + fp) > 0 else np.nan)\n",
        "specificity = np.nanmean(specificity_list)\n",
        "\n",
        "print(f\"Overall Sensitivity (Recall): {sensitivity:.3f}\")\n",
        "print(f\"Overall Specificity: {specificity:.3f}\")\n",
        "\n",
        "# --- Plotting ---\n",
        "metrics = ['Sensitivity', 'Specificity']\n",
        "values = [sensitivity * 100, specificity * 100]  # Convert to percentage\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "bars = plt.bar(metrics, values,\n",
        "               color=['skyblue', 'salmon'],\n",
        "               width=0.6, edgecolor='black', linewidth=0.8)\n",
        "\n",
        "# Add percentage labels on top\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1.0, f'{yval:.2f}%',\n",
        "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.title('Overall Sensitivity and Specificity', fontsize=13, fontweight='bold', pad=12)\n",
        "plt.ylabel('Score (%)', fontsize=11)\n",
        "plt.ylim(0, 110)  # Add headroom for labels\n",
        "plt.axhline(y=50, color='grey', linestyle='--', linewidth=0.8)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qsU8W7EY6ZUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Jaccard Index & Dice Score\n",
        "* Measure overlap between predicted and true classes using **Jaccard Index (IoU)** and **Dice Score**.\n"
      ],
      "metadata": {
        "id": "pNzXqwpxpTqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Compute confusion matrix and scores ---\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "jaccard_per_class = []\n",
        "dice_per_class = []\n",
        "\n",
        "for i in range(n_classes):\n",
        "    tp = cm[i, i]\n",
        "    fp = np.sum(cm[:, i]) - tp\n",
        "    fn = np.sum(cm[i, :]) - tp\n",
        "\n",
        "    # Jaccard Index\n",
        "    jaccard = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else np.nan\n",
        "    jaccard_per_class.append(jaccard)\n",
        "\n",
        "    # Dice Score\n",
        "    dice = 2*tp / (2*tp + fp + fn) if (2*tp + fp + fn) > 0 else np.nan\n",
        "    dice_per_class.append(dice)\n",
        "\n",
        "# Macro-average (overall)\n",
        "jaccard_index = np.nanmean(jaccard_per_class)\n",
        "dice_score = np.nanmean(dice_per_class)\n",
        "\n",
        "print(f\"Overall Jaccard Index: {jaccard_index:.3f}\")\n",
        "print(f\"Overall Dice Score: {dice_score:.3f}\")\n",
        "\n",
        "# --- Plotting ---\n",
        "metrics = ['Jaccard Index', 'Dice Score']\n",
        "values = [jaccard_index * 100, dice_score * 100]  # convert to %\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "bars = plt.bar(metrics, values,\n",
        "               color=['lightgreen', 'skyblue'],\n",
        "               width=0.6, edgecolor='black', linewidth=0.8)\n",
        "\n",
        "# Add percentage labels on top\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1.0, f'{yval:.2f}%',\n",
        "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.title('Overall Jaccard Index and Dice Score', fontsize=13, fontweight='bold', pad=12)\n",
        "plt.ylabel('Score (%)', fontsize=11)\n",
        "plt.ylim(0, 110)  # headroom for labels\n",
        "plt.axhline(y=50, color='grey', linestyle='--', linewidth=0.8)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "93MdRURn6cgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ PR-AUC (Precision-Recall AUC)\n",
        "* Evaluate model performance using the **area under the Precision-Recall curve**, especially useful for imbalanced datasets."
      ],
      "metadata": {
        "id": "nMHjtfDkEqYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Get true labels and predicted probabilities\n",
        "y_true = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)\n",
        "y_pred_probs = model.predict(test_dataset)\n",
        "\n",
        "# Handle binary or multiclass\n",
        "if y_pred_probs.shape[1] == 2:  # binary\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred_probs[:, 1])\n",
        "    pr_auc = auc(recall, precision)\n",
        "else:  # multiclass\n",
        "    pr_auc = {}\n",
        "    from sklearn.preprocessing import label_binarize\n",
        "    y_true_bin = label_binarize(y_true, classes=range(y_pred_probs.shape[1]))\n",
        "    for i in range(y_pred_probs.shape[1]):\n",
        "        precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
        "        pr_auc[i] = auc(recall, precision)\n",
        "\n",
        "print(\"PR-AUC:\", pr_auc)\n"
      ],
      "metadata": {
        "id": "ZNRPxpNYEqYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Log Loss / Cross-Entropy Loss\n",
        "* Evaluate prediction confidence using **log loss** (cross-entropy) between true and predicted probabilities."
      ],
      "metadata": {
        "id": "OrM9R_qBEqYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "y_true = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)\n",
        "y_pred_probs = model.predict(test_dataset)\n",
        "\n",
        "loss = log_loss(y_true, y_pred_probs)\n",
        "print(\"Log Loss / Cross-Entropy Loss:\", loss)\n"
      ],
      "metadata": {
        "id": "bK91hhyBEqYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Top-k Accuracy\n",
        "* Measure if the **true label** is among the model's **top k predicted classes** in multiclass classification."
      ],
      "metadata": {
        "id": "mA9pG-syEqY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-k accuracy automatically for multiclass\n",
        "k = 3  # you can change k\n",
        "top_k_acc = tf.keras.metrics.TopKCategoricalAccuracy(k=k)\n",
        "\n",
        "y_true = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)\n",
        "y_pred_probs = model.predict(test_dataset)\n",
        "\n",
        "# Convert binary labels to categorical if needed\n",
        "if y_pred_probs.shape[1] == 2 and len(np.unique(y_true)) == 2:\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    y_true_cat = to_categorical(y_true, num_classes=2)\n",
        "else:\n",
        "    y_true_cat = tf.keras.utils.to_categorical(y_true, num_classes=y_pred_probs.shape[1])\n",
        "\n",
        "top_k_acc.update_state(y_true_cat, y_pred_probs)\n",
        "print(f\"Top-{k} Accuracy:\", top_k_acc.result().numpy())"
      ],
      "metadata": {
        "id": "DNUPUOY8EqY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ G-Mean (Geometric Mean of Sensitivity & Specificity)\n",
        "* Compute the **G-Mean** to evaluate balanced classification performance."
      ],
      "metadata": {
        "id": "rmC4hXGOEqY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.concatenate([y.numpy() for x, y in test_dataset], axis=0)\n",
        "y_pred = np.argmax(model.predict(test_dataset), axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "if cm.shape[0] == 2:  # binary\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    g_mean = math.sqrt(sensitivity * specificity)\n",
        "else:  # multiclass: compute G-mean per class and average\n",
        "    sensitivity_list = []\n",
        "    specificity_list = []\n",
        "    for i in range(cm.shape[0]):\n",
        "        tp = cm[i, i]\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        tn = cm.sum() - (tp + fn + fp)\n",
        "        sensitivity_list.append(tp / (tp + fn) if (tp+fn)>0 else 0)\n",
        "        specificity_list.append(tn / (tn + fp) if (tn+fp)>0 else 0)\n",
        "    g_mean = np.mean(np.sqrt(np.array(sensitivity_list) * np.array(specificity_list)))\n",
        "\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "RrrEzpl9EqY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ðŸ”¥ Grad-CAM Visualization\n",
        "Generate **Grad-CAM heatmaps** to visualize the regions of input images that the **CNN** model focuses on for its predictions.\n"
      ],
      "metadata": {
        "id": "hVGrB2pvpmew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Grad-CAM\n",
        "* Gradient-weighted Class Activation Mapping\n",
        "* Highlights important regions in an image using gradients flowing into the last convolutional layer.  "
      ],
      "metadata": {
        "id": "mgduJ_UnRsZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def get_img_array(img_path, target_size=(224,224)):\n",
        "    \"\"\"Load and preprocess image\"\"\"\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = tf.keras.applications.densenet.preprocess_input(array)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"Generate Grad-CAM heatmap\"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    \"\"\"Overlay heatmap on original image\"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap_color, alpha, 0)\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Example Usage\n",
        "# -------------------------\n",
        "img_path = \"/content/drive/MyDrive/sample_dataset/test/10/157.jpg\"\n",
        "img_array = get_img_array(img_path, target_size=(224,224))\n",
        "\n",
        "# DenseNet121 last conv layer for Grad-CAM\n",
        "last_conv_layer_name = \"conv5_block16_2_conv\"\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "display_gradcam(img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "E9mzi2h7R9Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def display_original_and_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    \"\"\"Display original image and Grad-CAM side by side with titles\"\"\"\n",
        "\n",
        "    # Load original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create Grad-CAM overlay\n",
        "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap_color, alpha, 0)\n",
        "\n",
        "    # Plot side by side\n",
        "    plt.figure(figsize=(12,6))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original Image\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Grad-CAM image\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title(\"Grad-CAM\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Example Usage\n",
        "# -------------------------\n",
        "img_path = \"/content/drive/MyDrive/sample_dataset/test/10/157.jpg\"\n",
        "img_array = get_img_array(img_path, target_size=(224,224))\n",
        "\n",
        "# Grad-CAM heatmap\n",
        "last_conv_layer_name = \"conv5_block16_2_conv\"\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "# Display comparison\n",
        "display_original_and_gradcam(img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "DdrTChMmlw2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def get_img_array(img_path, target_size=(224,224)):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = tf.keras.applications.densenet.preprocess_input(array)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_original_and_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    # Load original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create Grad-CAM overlay\n",
        "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap_color, alpha, 0)\n",
        "\n",
        "    # Plot side by side\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original Image\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title(\"Grad-CAM\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Main function\n",
        "# -------------------------\n",
        "def gradcam_one_image_per_class(model, test_directory, last_conv_layer_name=\"conv5_block16_2_conv\"):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM for ONE image from each true class folder.\n",
        "    \"\"\"\n",
        "    # Get class names from folder names\n",
        "    class_names = sorted([d for d in os.listdir(test_directory) if os.path.isdir(os.path.join(test_directory, d))])\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_path = os.path.join(test_directory, class_name)\n",
        "\n",
        "        # Pick the first image from the folder\n",
        "        img_name = os.listdir(class_path)[0]\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "        # Preprocess for model\n",
        "        img_array = get_img_array(img_path, target_size=(224,224))\n",
        "\n",
        "        # Grad-CAM heatmap\n",
        "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "        # Display\n",
        "        display_original_and_gradcam(img_path, heatmap)\n",
        "\n",
        "# -------------------------\n",
        "# Example usage\n",
        "# -------------------------\n",
        "test_directory = \"/content/drive/MyDrive/sample_dataset/train\"\n",
        "gradcam_one_image_per_class(model, test_directory)\n"
      ],
      "metadata": {
        "id": "rx7Mym8OpMdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "def get_img_array(img_path, target_size=(224,224)):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = tf.keras.applications.densenet.preprocess_input(array)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_original_and_gradcam(img_path, heatmap, alpha=0.4, class_name=None, pred_prob=None):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap_color, alpha, 0)\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original Image\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    title_text = \"Grad-CAM\"\n",
        "    if class_name is not None and pred_prob is not None:\n",
        "        title_text += f\"\\nPred: {class_name} ({pred_prob*100:.1f}%)\"\n",
        "    plt.title(title_text, fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def gradcam_one_image_per_class(model, test_directory, last_conv_layer_name=\"conv5_block16_2_conv\"):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM for ONE image from each true class folder.\n",
        "    \"\"\"\n",
        "    # Get class names from folder names\n",
        "    class_names = sorted([d for d in os.listdir(test_directory) if os.path.isdir(os.path.join(test_directory, d))])\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_path = os.path.join(test_directory, class_name)\n",
        "\n",
        "        # Pick the first image from the folder\n",
        "        img_name = os.listdir(class_path)[0]\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "        # Preprocess\n",
        "        img_array = get_img_array(img_path, target_size=(224,224))\n",
        "\n",
        "        # Grad-CAM heatmap\n",
        "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "        # Prediction\n",
        "        preds = model.predict(img_array, verbose=0)\n",
        "        pred_index = np.argmax(preds[0])\n",
        "        pred_prob = preds[0][pred_index]\n",
        "        # Map predicted index to folder names\n",
        "        pred_class_name = class_names[pred_index] if pred_index < len(class_names) else f\"Class {pred_index}\"\n",
        "\n",
        "        # Display side-by-side\n",
        "        display_original_and_gradcam(img_path, heatmap, class_name=pred_class_name, pred_prob=pred_prob)\n",
        "\n",
        "# -------------------------\n",
        "# Example usage\n",
        "# -------------------------\n",
        "test_directory = \"/content/drive/MyDrive/sample_dataset/train\"\n",
        "gradcam_one_image_per_class(model, test_directory)\n"
      ],
      "metadata": {
        "id": "ZhJt0HEmnwnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "\n",
        "def get_img_array(img_path, target_size=(224,224)):\n",
        "    \"\"\"Load image and convert to array suitable for model input\"\"\"\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = tf.keras.applications.densenet.preprocess_input(array)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"Compute Grad-CAM heatmap for a single image\"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_original_and_gradcam(img_path, heatmap, true_class=None, pred_class=None, pred_prob=None, alpha=0.4):\n",
        "    \"\"\"Display original image and Grad-CAM overlay side by side\"\"\"\n",
        "    # Load original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create Grad-CAM overlay\n",
        "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap_color, alpha, 0)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Original Image\\nTrue: {true_class}\", fontsize=12, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    title_text = \"Grad-CAM\"\n",
        "    if pred_class is not None and pred_prob is not None:\n",
        "        title_text += f\"\\nPred: {pred_class} ({pred_prob*100:.1f}%)\"\n",
        "    plt.title(title_text, fontsize=12, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Main function\n",
        "# -------------------------\n",
        "\n",
        "def gradcam_one_image_per_class(model, test_directory, last_conv_layer_name=\"conv5_block16_2_conv\"):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM for ONE image from each class folder.\n",
        "    \"\"\"\n",
        "    # Automatically detect class folders\n",
        "    class_names = sorted([d for d in os.listdir(test_directory) if os.path.isdir(os.path.join(test_directory, d))])\n",
        "\n",
        "    for true_class in class_names:\n",
        "        class_path = os.path.join(test_directory, true_class)\n",
        "\n",
        "        # Pick the first image in the folder\n",
        "        img_name = os.listdir(class_path)[0]\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "        # Preprocess\n",
        "        img_array = get_img_array(img_path, target_size=(224,224))\n",
        "\n",
        "        # Grad-CAM heatmap\n",
        "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "        # Prediction\n",
        "        preds = model.predict(img_array, verbose=0)\n",
        "        pred_index = np.argmax(preds[0])\n",
        "        pred_prob = float(preds[0][pred_index])\n",
        "\n",
        "        # Map prediction index to class name safely\n",
        "        pred_class = class_names[pred_index] if pred_index < len(class_names) else f\"Class {pred_index}\"\n",
        "\n",
        "        # Display\n",
        "        display_original_and_gradcam(img_path, heatmap, true_class=true_class, pred_class=pred_class, pred_prob=pred_prob)\n",
        "\n",
        "# -------------------------\n",
        "# Example usage\n",
        "# -------------------------\n",
        "test_directory = \"/content/drive/MyDrive/sample_dataset/train\"\n",
        "gradcam_one_image_per_class(model, test_directory)\n"
      ],
      "metadata": {
        "id": "GX7P1X0jqRUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Grad-CAM++\n",
        "* Improved version of Grad-CAM that better localizes multiple occurrences of objects."
      ],
      "metadata": {
        "id": "WRsvXb5CtAzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Grad-CAM++ helper functions\n",
        "# -------------------------\n",
        "def make_gradcam_plus_plus_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"\n",
        "    Compute Grad-CAM++ heatmap for a single image\n",
        "    Reference: Chattopadhyay et al., Grad-CAM++ (2018)\n",
        "    \"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape1:\n",
        "        with tf.GradientTape() as tape2:\n",
        "            conv_outputs, predictions = grad_model(img_array)\n",
        "            if pred_index is None:\n",
        "                pred_index = tf.argmax(predictions[0])\n",
        "            class_channel = predictions[:, pred_index]\n",
        "        grads = tape2.gradient(class_channel, conv_outputs)  # first-order gradient\n",
        "    grads2 = tape1.gradient(grads, conv_outputs)             # second-order gradient\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    grads = grads[0]\n",
        "    grads2 = grads2[0]\n",
        "\n",
        "    # Compute alpha for Grad-CAM++\n",
        "    numerator = grads2\n",
        "    denominator = 2 * grads2 + tf.reduce_sum(conv_outputs * grads2, axis=(0, 1))\n",
        "    denominator = tf.where(denominator != 0.0, denominator, tf.ones_like(denominator))  # avoid div by 0\n",
        "    alphas = numerator / denominator\n",
        "\n",
        "    weights = tf.reduce_sum(tf.nn.relu(alphas * tf.nn.relu(grads)), axis=(0, 1))\n",
        "    heatmap = tf.reduce_sum(weights * conv_outputs, axis=-1)\n",
        "\n",
        "    # Normalize\n",
        "    heatmap = tf.maximum(heatmap, 0)\n",
        "    heatmap /= tf.math.reduce_max(heatmap + 1e-10)\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# -------------------------\n",
        "# Display function for Grad-CAM++\n",
        "# -------------------------\n",
        "def display_original_and_gradcam_plus_plus(img_path, heatmap, alpha=0.4):\n",
        "    # Load original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create Grad-CAM++ overlay\n",
        "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1-alpha, heatmap_color, alpha, 0)\n",
        "\n",
        "    # Plot side by side\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original Image\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title(\"Grad-CAM++\", fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Main function for Grad-CAM++\n",
        "# -------------------------\n",
        "def gradcam_plus_plus_one_image_per_class(model, test_directory, last_conv_layer_name=\"conv5_block16_2_conv\"):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM++ for ONE image from each true class folder.\n",
        "    \"\"\"\n",
        "    # Get class names from folder names\n",
        "    class_names = sorted([d for d in os.listdir(test_directory) if os.path.isdir(os.path.join(test_directory, d))])\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_path = os.path.join(test_directory, class_name)\n",
        "\n",
        "        # Pick the first image from the folder\n",
        "        img_name = os.listdir(class_path)[0]\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "        # Preprocess for model\n",
        "        img_array = get_img_array(img_path, target_size=(224,224))\n",
        "\n",
        "        # Grad-CAM++ heatmap\n",
        "        heatmap = make_gradcam_plus_plus_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "        # Display\n",
        "        display_original_and_gradcam_plus_plus(img_path, heatmap)\n",
        "\n",
        "# -------------------------\n",
        "# Example usage\n",
        "# -------------------------\n",
        "test_directory = \"/content/drive/MyDrive/sample_dataset/train\"\n",
        "gradcam_plus_plus_one_image_per_class(model, test_directory)\n"
      ],
      "metadata": {
        "id": "zCFF11AKtAzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Score-CAM\n",
        "* Generates heatmaps by weighting activation maps with forward-pass scores, no gradients needed.  "
      ],
      "metadata": {
        "id": "y4HU4zEFR4Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZWaQEKo0eYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Faster Score-CAM  \n",
        "A speed-optimized version of Score-CAM that reduces the number of forward passes while generating heatmaps.\n"
      ],
      "metadata": {
        "id": "P-68G7OKEzXS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IETLyq-QE2x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ LIME\n",
        "* Explains model predictions by perturbing superpixels and fitting a local interpretable model."
      ],
      "metadata": {
        "id": "N9aNttdRR5Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "dGLhQhCmRkst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def plot_lime_single_image(model, img_path, class_names, num_samples=1000):\n",
        "    # Load image and convert to array\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Prediction function for LIME\n",
        "    def predict_fn(images):\n",
        "        images_preprocessed = tf.keras.applications.densenet.preprocess_input(images.astype(np.float32))\n",
        "        return model.predict(images_preprocessed)\n",
        "\n",
        "    # LIME explainer\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "    explanation = explainer.explain_instance(\n",
        "        np.uint8(img_array),\n",
        "        classifier_fn=predict_fn,\n",
        "        top_labels=1,\n",
        "        hide_color=0,\n",
        "        num_samples=num_samples\n",
        "    )\n",
        "\n",
        "    # Get top predicted class explanation\n",
        "    top_class = explanation.top_labels[0]\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        top_class,\n",
        "        positive_only=True,\n",
        "        num_features=10,\n",
        "        hide_rest=False\n",
        "    )\n",
        "    lime_img = mark_boundaries(temp / 255.0, mask)\n",
        "\n",
        "    # Plot original and LIME side by side\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img_array.astype(np.uint8))\n",
        "    plt.title(\"Original Image\", fontsize=12, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(lime_img)\n",
        "    plt.title(f\"LIME Explanation\\nPred: {class_names[top_class]}\", fontsize=12, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "test_image_path = \"/content/drive/MyDrive/sample_dataset/train/10/130.jpg\"\n",
        "plot_lime_single_image(model, test_image_path, class_names)\n"
      ],
      "metadata": {
        "id": "iwSyCzuGvI-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3LpccAmZwZUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ðŸ”¥ SHAP\n",
        "* SHapley Additive exPlanations\n",
        "* SHAP uses **Shapley values** to show each input pixel's contribution to the model's prediction, highlighting important regions in the image.\n"
      ],
      "metadata": {
        "id": "blQ-5pvl1irw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# -------------------------\n",
        "# SHAP visualization function\n",
        "# -------------------------\n",
        "def plot_shap_image(model, img_path, class_names, num_samples=50):\n",
        "    \"\"\"\n",
        "    Generate SHAP explanation for a single image.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_input = np.expand_dims(img_array, axis=0)\n",
        "    img_input_pre = tf.keras.applications.densenet.preprocess_input(img_input.astype(np.float32))\n",
        "\n",
        "    # Model prediction\n",
        "    preds = model.predict(img_input_pre)\n",
        "    pred_index = np.argmax(preds[0])\n",
        "    pred_prob = preds[0][pred_index]\n",
        "    pred_class_name = class_names[pred_index]\n",
        "\n",
        "    # Define a function for SHAP to call\n",
        "    def f(x):\n",
        "        x_pre = tf.keras.applications.densenet.preprocess_input(x.astype(np.float32))\n",
        "        return model.predict(x_pre)\n",
        "\n",
        "    # SHAP DeepExplainer\n",
        "    # Use a small background dataset for efficiency (here just using the same image multiple times)\n",
        "    background = img_input_pre\n",
        "    explainer = shap.DeepExplainer(model, background)\n",
        "    shap_values = explainer.shap_values(img_input_pre)\n",
        "\n",
        "    # Convert SHAP values to a heatmap for the predicted class\n",
        "    heatmap = np.mean(np.abs(shap_values[pred_index]), axis=-1)[0]  # shape: (224,224)\n",
        "    heatmap = heatmap / np.max(heatmap + 1e-10)  # normalize 0-1\n",
        "\n",
        "    # Overlay heatmap on image\n",
        "    img_uint8 = img_array.astype(np.uint8)\n",
        "    cmap = plt.get_cmap('jet')\n",
        "    heatmap_color = cmap(heatmap)[...,:3]  # RGB\n",
        "    superimposed_img = (0.6*img_uint8/255.0 + 0.4*heatmap_color)\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 1)\n",
        "\n",
        "    # Plot side by side\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img_uint8)\n",
        "    plt.title(\"Original Image\", fontsize=12, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title(f\"SHAP Explanation\\nPred: {pred_class_name} ({pred_prob*100:.1f}%)\",\n",
        "              fontsize=12, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Example usage\n",
        "# -------------------------\n",
        "test_image_path = \"/content/drive/MyDrive/sample_dataset/train/10/130.jpg\"\n",
        "plot_shap_image(model, test_image_path, class_names)\n"
      ],
      "metadata": {
        "id": "drbbx8yp1mlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}